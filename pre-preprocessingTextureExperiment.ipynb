{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-preprocessing 2-photon data with texture experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing 2p imaging data for texture representation in collaboration with Dr.Gardner@Standord\n",
    "# modified from pre-preprocessingVSExperiment.ipynb\n",
    "# last update @190626\n",
    "# written by RA\n",
    "\n",
    "import scipy.io as sio\n",
    "%matplotlib nbagg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "from pims import ND2_Reader\n",
    "import tifffile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the following line to the name of the consecutive (same ROI) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = \"M190213_18222\"\n",
    "# iexp = '1'\n",
    "# iseries = ('4','5','6','8','9','10')\n",
    "# experiment = \"M190421_18228\"\n",
    "# iseries = '2'\n",
    "# expset = ('4','5','6','8','9','10')\n",
    "#iseries = '1'\n",
    "#expset = ('3','4','5','7','8','9')\n",
    "experiment = \"M190625_18273\"\n",
    "iseries = '1'\n",
    "expset = ('2')\n",
    "expType = ('texture',)\n",
    "#expType = ('ori','spont','driver','driver','spont','ori')\n",
    "for i in range(len(expset)):\n",
    "    foo = experiment+'_'+iseries+'_'+expset[i]\n",
    "    print(foo, ' is ', expType[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the filenames for data log, 2 photon data, and the ET video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_folder_data_log = \"//Labserver/data/MOUSE/LOGS/VS_LOGS\" # for Win, not work in Linux\n",
    "master_folder_nd2 = \"//NCB-LABSERVER6/data/MOUSE/IMAGING/GCAMP/\"\n",
    "#master_folder_nd2 = \"//LABSERVER5/data/MOUSE/IMAGING/GCAMP/\"\n",
    "master_folder_ET = \"//NCB-LABSERVER6/data/MOUSE/EyeTracking/GCaMP/\"\n",
    "#print(os.path.join(master_folder_data_log, experiment))\n",
    "#len(os.listdir(os.path.join(master_folder_data_log, experiment)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental setting\n",
    "do_ET = False\n",
    "is_driverCell = False\n",
    "\n",
    "data_log_filename = []\n",
    "nd2_filename = []\n",
    "ET_filename =[]\n",
    "ntri = [] # #trial\n",
    "for i in range(len(expset)): # loop for each iseries\n",
    "    data_log_filename.append(os.path.join(master_folder_data_log, experiment+'_'+iseries+'_'+expset[i]+'.mat'))\n",
    "    assert os.path.isfile(data_log_filename[-1]), 'No log data found!!: '+data_log_filename[-1]\n",
    "    print('found a data_log:',os.path.join(master_folder_data_log, experiment+'_'+iseries+'_'+expset[i]+'.mat'))\n",
    "            \n",
    "    nd2_filename.append(os.path.join(master_folder_nd2, experiment, experiment+'-'+iseries+'-'+expset[i]+'.nd2'))\n",
    "    assert os.path.isfile(nd2_filename[-1]), 'No nd2 data found!!: '+nd2_filename[-1]\n",
    "    print('found a nd2 file:', nd2_filename[-1])\n",
    "    \n",
    "    if do_ET:\n",
    "        \n",
    "        print(os.path.join(master_folder_ET, experiment,iseries,expset[i]))\n",
    "        ET_filename_tmp = []\n",
    "        ET_subdir = os.path.join(master_folder_ET, experiment,iseries,expset[i])\n",
    "        n_ETfiles = len([name for name in os.listdir(ET_subdir) if os.path.isfile(os.path.join(ET_subdir,name)) and name.endswith('.eye')])\n",
    "        for j in range(n_ETfiles):\n",
    "            ET_filename_tmp.append(os.path.join(ET_subdir, experiment+'_'+str(j+1)+'.eye'))\n",
    "            assert os.path.isfile(ET_filename_tmp[-1]), 'No EyeTracking data found!!'\n",
    "        \n",
    "        assert (len(ET_filename_tmp) == 195 and expType[i] == 'ori') or (len(ET_filename_tmp) == 1 and expType[i] == 'spont') or (len(ET_filename_tmp) == 1 and expType[i] == 'driver') or (len(ET_filename_tmp) == 1 and expType[i] == 'driver_30ms'), 'Mismatch trial number and number of .eye files'\n",
    "        ET_filename.append(ET_filename_tmp)\n",
    "        ntri.append(len(ET_filename_tmp))\n",
    "    else: # HACK for texture exp...\n",
    "        ntri.append(96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the folders where all the post-processed data will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_analysis_folder = \"//NCB-LABSERVER6/data/MOUSE/IMAGING/GCAMP/\" # same folder as raw .nd2 data\n",
    "experiment_folder = os.path.join(master_analysis_folder, experiment)\n",
    "folders_to_make = [\"ET\", \"2P\", \"Preprocessed\"] # put everything in this folder\n",
    "\n",
    "\n",
    "for folder in  folders_to_make:\n",
    "    new_path = os.path.join(master_analysis_folder, experiment_folder, folder)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Eye video to .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "if do_ET:\n",
    "    ET_n_frame = []\n",
    "    for j in range(len(expset)):\n",
    "        ET_n_frame_tmp = []\n",
    "        for i in tqdm(range(len(ET_filename[j]))):\n",
    "            try: \n",
    "                new_ET_foldername = os.path.join(experiment_folder, \"ET/\" ,iseries)\n",
    "                new_ET_filename = os.path.join(new_ET_foldername, experiment+'_'+expset[j]+'_'+ str(i+1)+\".mp4\")\n",
    "                ET_video = open_raw_eye_file(ET_filename[j][i])\n",
    "                if not os.path.exists(new_ET_foldername):\n",
    "                    os.makedirs(new_ET_foldername)\n",
    "                ET_n_frame_tmp.append(ET_video.n_frames)\n",
    "                if not os.path.exists(new_ET_filename):\n",
    "                    out = cv2.VideoWriter(new_ET_filename,\\\n",
    "                                  cv2.VideoWriter_fourcc('H','2','6','4'), 30, (ET_video.width, ET_video.height))\n",
    "\n",
    "                    for frame in ET_video.img_data:\n",
    "                        out.write(cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB))\n",
    "                    out.release()\n",
    "            except:\n",
    "                print(ET_filename[j][i], ' can not be converted properly...')\n",
    "                ET_n_frame_tmp.append(0) # assign no frame for errornous trial.\n",
    "        ET_n_frame.append(ET_n_frame_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: concatenate all sessions for training dataset\n",
    "# ET_n_frame = []\n",
    "# new_ET_filename = os.path.join(experiment_folder, \"ET/\", experiment+\".mp4\")\n",
    "# out = cv2.VideoWriter(new_ET_filename,\\\n",
    "#                       cv2.VideoWriter_fourcc('H','2','6','4'), 30, (ET_video.width, ET_video.height))\n",
    "# for i in range(len(ET_filename)):\n",
    "#     ET_video = open_raw_eye_file(ET_filename[i])\n",
    "#     print(i,\" th trial's number of frames: \", ET_video.n_frames)\n",
    "#     ET_n_frame.append(ET_video.n_frames)\n",
    "#     #    plt.imshow(ET_video.img_data[100])\n",
    "#     for frame in ET_video.img_data:\n",
    "#         out.write(cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB))\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert nd2 to tiff for suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoP_video = []; n_frame = []\n",
    "for i in range(len(expset)):\n",
    "    twoP_video.append(ND2_Reader(nd2_filename[i]))\n",
    "    n_frame.append(twoP_video[-1].sizes['t'])\n",
    "print(np.sum(n_frame), ' frames in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check 2p image\n",
    "# plt.figure()\n",
    "# plt.title(twoP_video[0].sizes)\n",
    "# plt.imshow(twoP_video[0][1000], cmap='gray', vmin=0, vmax=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty tensor to put the entire nd2 file in, then we will save that tensor as a tiff file.\n",
    "\n",
    "Shape of tensor is (time, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_2p_frames = np.zeros((np.sum(n_frame), twoP_video[0].sizes['y'], twoP_video[0].sizes['x']), dtype=np.uint16)\n",
    "for j in range(len(expset)):\n",
    "    for i in tqdm(range(n_frame[j])):   \n",
    "        all_2p_frames[int(np.sum(n_frame[:j]))+i] = twoP_video[j][i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(os.path.join(experiment_folder, \"2P/\", experiment+'_'+iseries, experiment+'_'+iseries+\".tiff\"))\n",
    "assert not os.path.isfile(os.path.join(experiment_folder, \"2P/\", experiment+'_'+iseries, experiment+'_'+iseries+\".tiff\")), 'Tiff file already exsit!'\n",
    "os.makedirs(os.path.join(experiment_folder, \"2P/\", experiment+'_'+iseries))\n",
    "tifffile.imsave(data=all_2p_frames, file=os.path.join(experiment_folder, \"2P/\", experiment+'_'+iseries, experiment+'_'+iseries+\".tiff\"), bigsize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run suite2p!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Log and obtain alignment vectors to stimulus onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logs = []\n",
    "for i in range(len(expset)):\n",
    "    data_logs.append(sio.loadmat(data_log_filename[i]))\n",
    "dac_sampling_rate = 10000 #10Khz sampling rate of 2p DAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on what each column of logging contains go here:\n",
    "http://172.17.150.6/mediawiki/index.php?title=2P\n",
    "\n",
    "The first column is the timestamps of the DAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_ET:\n",
    "    ET_timestamp = []\n",
    "    for iexp in range(len(expset)):\n",
    "        # detect the timestamps for each frame, removing the missing frames (on the assumption that last one is missing...)\n",
    "        frameEx_ET_ttl = data_logs[iexp]['AIdata'][:, 8] # rise for 5 msec at frame onset\n",
    "        ET_on_off_trial_ttl = data_logs[iexp]['AIdata'][:, 7]\n",
    "        # TTL signal goes from zero to a value of around 3.\n",
    "        # So we find the point\n",
    "        ET_frame_ttl_inTrial = frameEx_ET_ttl.copy()\n",
    "        ET_frame_ttl_inTrial[ET_on_off_trial_ttl < 1.0 ] = 0.0 # pad non-trial period with 0 \n",
    "        diff_frameEx_ttl = np.hstack((0, np.diff(ET_frame_ttl_inTrial)))\n",
    "\n",
    "        # sanity check that missing frame is no more than 1 in each trials\n",
    "    #    frame_onset_idx = np.where(diff_frameEx_ttl < -1.5)[0] # fall in ttl\n",
    "        frame_onset_idx = np.where(diff_frameEx_ttl > 1.5)[0] # rise in ttl (in trial)\n",
    "        frame_onset_idx_whole = np.where(np.hstack((0, np.diff(frameEx_ET_ttl))) > 1.5)[0] # rise in ttl (in and out of trial)\n",
    "        gap_frame_idx = np.hstack((0,np.where(np.diff(frame_onset_idx)>0.5*dac_sampling_rate)[0]+1,frame_onset_idx.shape[0]-1))\n",
    "        assert np.max(np.diff(gap_frame_idx)-np.array(ET_n_frame[iexp])) < 2, str(np.max(np.diff(gap_frame_idx)-np.array(ET_n_frame[iexp])))+' missing frames in some trials!!'\n",
    "\n",
    "\n",
    "        # extract ET frame onset timestamps\n",
    "        ET_timestamp_sub = []\n",
    "        for itr in range(len(ET_n_frame[iexp])):\n",
    "            strt_idx = np.where(frame_onset_idx_whole >= frame_onset_idx[gap_frame_idx[itr]])[0][0]\n",
    "            ET_timestamp_sub.append(data_logs[iexp]['AIdata'][frame_onset_idx_whole[strt_idx:(strt_idx+ET_n_frame[iexp][itr])],0])\n",
    "    #        ET_timestamp_sub.append(data_logs[iexp]['AIdata'][frame_onset_idx[gap_frame_idx[itr]]:frame_onset_idx[gap_frame_idx[itr]]+ET_n_frame[iexp][itr],0])\n",
    "        ET_timestamp.append(ET_timestamp_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all the trial information and converting it to uncorrected indeces of the DAC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now extract 2p frame onset timing (complicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoP_frame_onset =[]\n",
    "for j in range(len(expset)):\n",
    "    signal_2p_aq = data_logs[j]['AIdata'][:, 2].copy()\n",
    "\n",
    "    # Values of 2p ttl fluctuate from around 3 when not aqcuiring to 0 while frame aqcuiring.\n",
    "    signal_2p_aq[np.where(signal_2p_aq<1)] = 0\n",
    "    signal_2p_aq[np.where(signal_2p_aq>1)] = 1\n",
    "    diff_2p_ttl = np.diff(signal_2p_aq)\n",
    "\n",
    "\n",
    "    twoP_ttl_rise = np.where(diff_2p_ttl > 0.5)[0]\n",
    "    twoP_ttl_fall = np.where(diff_2p_ttl < -0.5)[0]\n",
    "    twoP_frame_onset_tmp = []\n",
    "    for i in tqdm(range(twoP_ttl_rise.shape[0])): # rise and fall within 20 timebin (=2msec) is defined as frame \n",
    "        if np.any(np.all(np.vstack((twoP_ttl_fall>twoP_ttl_rise[i],twoP_ttl_fall<twoP_ttl_rise[i]+20)),axis=0)):\n",
    "            twoP_frame_onset_tmp.append(data_logs[j]['AIdata'][twoP_ttl_rise[i],0])\n",
    "    twoP_frame_onset.append(twoP_frame_onset_tmp)\n",
    "    \n",
    "    # find the number of frames for each repeats \n",
    "    # start/end of each trial was defined as frame interval > 100 msec\n",
    "    int_thresh = 0.1 # 100 msec for interval thresholding \n",
    "    frame_int = np.diff(twoP_frame_onset[j])\n",
    "    twoP_frame_repeat = np.hstack((0, np.cumsum(frame_int>int_thresh)))\n",
    " \n",
    "    #Now let's assert that the detected frame number from ttl matchs frame number of nd2 data.\n",
    "    print('detected TTL peaks : ',len(twoP_frame_onset[j]))\n",
    "    print('actual frame number: ',n_frame[j])\n",
    "    # the mismatch in number is ok, as 2p acqusition is stopped manually and can continues after VS end\n",
    "    #assert len(twoP_frame_onset[j])==n_frame[j] or expType[j]!='ori', 'Missing frames....'\n",
    "   # print(len(twoP_frame_onset[j]),n_frame[j] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First assertion, do the number of trials logged by BVS matches the number of times the photodiode black square shows up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert ACTUAL_stim_onset_indeces.shape[0] == int_stim_onset_block_trial.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second assertion, is the difference in stimulus onset of BVS and actual stimulus onset as measured by the photodiode within one second?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert (np.abs(ACTUAL_stim_onset_indeces-int_stim_onset_block_trial) < dac_sampling_rate).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open  suite2p analyzed 2p Data and splice it by trial type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this section necessary? (can separately load npy files for analysis...)\n",
    "suite2p_F_filename = os.path.join(experiment_folder, \"2P\", experiment+'_'+iseries, \"suite2p/plane0/F.npy\")\n",
    "suite2p_is_cell_filename = os.path.join(experiment_folder, \"2P\", experiment+'_'+iseries, \"suite2p/plane0/iscell.npy\")\n",
    "suite2p_spks_filename = os.path.join(experiment_folder, \"2P\", experiment+'_'+iseries, \"suite2p/plane0/spks.npy\")\n",
    "suite2p_stat_filename = os.path.join(experiment_folder, \"2P\", experiment+'_'+iseries,  \"suite2p/plane0/stat.npy\")\n",
    "try:\n",
    "    raw_traces = np.load(suite2p_F_filename)\n",
    "    spike_traces = np.load(suite2p_spks_filename)\n",
    "    is_cell = np.load(suite2p_is_cell_filename)\n",
    "    stat = np.load(suite2p_stat_filename)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Please ensure that you've ran suite2p on the 2p tiff file before running this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract roi info from stat.npy\n",
    "nroi = stat.shape[0]\n",
    "twoP_rois = np.zeros((512,512,nroi)) # note that after motion correction data size can be smaller than 512 x 512\n",
    "twoP_med = np.zeros((2,nroi)) \n",
    "for iroi in range(nroi):\n",
    "    twoP_med[:,iroi] = stat[iroi]['med']\n",
    "    for ipix in range(stat[iroi]['xpix'].shape[0]):\n",
    "        twoP_rois[stat[iroi]['ypix'][ipix], stat[iroi]['xpix'][ipix],iroi] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_driverCell:\n",
    "    dc_idx = 24 # index for driver_cell (0-indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplabcut things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do it on GPU server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save everything in hdf5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save everything in HDF5 to load in matlab\n",
    "hdf5_filename = os.path.join(experiment_folder,'Preprocessed/'+experiment+'_'+iseries+'.h5')\n",
    "import h5py\n",
    "with h5py.File(hdf5_filename, 'w') as f:\n",
    "    dt= h5py.special_dtype(vlen=float) # I don't know what it means...\n",
    "#     f.create_dataset('raw_traces', data = raw_traces)\n",
    "#     f.create_dataset('spike_traces', data = spike_traces)\n",
    "#     f.create_dataset('is_cell', data = is_cell)\n",
    " #   f.create_dataset('stat', data = stat)\n",
    "    f.create_dataset('twoP_med', data = twoP_med)\n",
    "    f.create_dataset('twoP_rois', data = twoP_rois)\n",
    "    f.create_dataset('twoP_n_frame',data=n_frame)\n",
    "    expset_list = [int(x) for x in expset]\n",
    "    f.create_dataset('expSet',data=np.array(expset_list))\n",
    "#    f.create_dataset('expType',data=expType)\n",
    "    if is_driverCell:\n",
    "        f.create_dataset('dc_idx',data=dc_idx+1) # change to 1-indexing.\n",
    "    f.create_dataset('ntri',data=ntri) \n",
    "    for i in range(len(expset)):\n",
    "        grp = f.create_group(str(expset[i]))\n",
    "        grp.create_dataset('twoP_frame_onset',data = np.array(twoP_frame_onset[i]))\n",
    "        grp.create_dataset('expType', data = expType[i])\n",
    "        if do_ET:\n",
    "            if len(ET_timestamp[i])==1:\n",
    "                grp.create_dataset('ET_timestamp', data = ET_timestamp[i])\n",
    "            else:\n",
    "                grp.create_dataset('ET_timestamp', data = ET_timestamp[i],dtype=dt) # dtype for list of >1 elements\n",
    "            if i > 0: print('a'); continue # hack in calse len(expSet)==1\n",
    "    #         grp.create_dataset('pupilCenterX', data =pupilCenterX[i],dtype=dt)\n",
    "    #         grp.create_dataset('pupilCenterY', data =pupilCenterY[i],dtype=dt)\n",
    "    #         grp.create_dataset('pupilArea', data = pupilArea[i],dtype=dt)\n",
    "            grp.create_dataset('ET_n_frame',data=ET_n_frame[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoPhotonTrial:\n",
    "    def __init__(self, experiment, feedback_type, orientation, start_time, stim_time, response_time, end_time,\n",
    "                 feedback_ended_time, list_of_cell_traces=None, list_of_ET_frames=None):\n",
    "        self.experimet = experiment\n",
    "        self.feedback_type = feedback_type\n",
    "        self.orientation = orientation\n",
    "        self.start_time = start_time\n",
    "        self.stim_time = stim_time\n",
    "        self.response_time = response_time\n",
    "        self.end_time = end_time\n",
    "        self.list_of_cell_traces = list_of_cell_traces\n",
    "        self.list_of_ET_frames = list_of_ET_frames\n",
    "        self.length = end_time - start_time\n",
    "        \n",
    "    def __gt__(self, obj):\n",
    "        return self.length > obj.length\n",
    "\n",
    "    def __ge__(self, obj):\n",
    "        return self.length >= obj.length\n",
    "\n",
    "    def __lt__(self, obj):\n",
    "        return self.length < obj.length\n",
    "\n",
    "    def __le__(self, obj):\n",
    "        return self.length <= obj.length\n",
    "\n",
    "    def get_feedback_type_string(self):\n",
    "        if self.feedback_type == -1:\n",
    "            return \"INCORRECT\"\n",
    "        elif self.feedback_type == 0:\n",
    "            return \"TIMEOUT\"\n",
    "        elif self.feedback_type == 1:\n",
    "            return \"CORRECT\"\n",
    "        else:\n",
    "            raise IndexError(\"Unkown feedback type:\", self.feed_back_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    def __init__(self, height, width, n_frames, img_data, time_stamps):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.n_frames = n_frames\n",
    "    \n",
    "        self.img_data = img_data\n",
    "        self.time_stamps = time_stamps\n",
    "\n",
    "def open_raw_eye_file(filename):\n",
    "    with open(filename, 'rb') as fid:\n",
    "        version = int(np.frombuffer(fid.read(4), dtype=np.uint32)[0])\n",
    "        width = int(np.frombuffer(fid.read(4), dtype=np.uint32)[0])\n",
    "        height = int(np.frombuffer(fid.read(4), dtype=np.uint32)[0])\n",
    "        n_frames = int(np.frombuffer(fid.read(4), dtype=np.uint32)[0])\n",
    "        pixel_format = int(np.frombuffer(fid.read(4), dtype=np.uint32)[0])\n",
    "        \n",
    "        if pixel_format == 8:\n",
    "            img_data = np.frombuffer(fid.read(height*width*n_frames), dtype=np.uint8)\n",
    "            img_data = np.reshape(img_data, (n_frames, height, width))\n",
    "        elif pixel_format == 16:\n",
    "            # Convert it to 8bits so we can easily save it to mp4.\n",
    "            img_data = np.frombuffer(fid.read(height*width*n_frames*2), dtype=np.uint16)/256\n",
    "            img_data = img_data.astype(np.uint8)\n",
    "            img_data = np.reshape(img_data, (n_frames, height, width))\n",
    "        else:\n",
    "            print(pixel_format)\n",
    "            raise NotImplemented(\"This bit format is not yet implemented, fix it Fed! >:()\")\n",
    "        \n",
    "        time_stamps = np.frombuffer(fid.read(n_frames*4), dtype=np.uint32)\n",
    "\n",
    "\n",
    "    return Video(height, width, n_frames, img_data, time_stamps)\n",
    "\n",
    "\n",
    "def calculate_df_f0(traces, baseline=None, std_norm=False):\n",
    "    # Use entire video for baseline if no baseline given\n",
    "    if baseline is None:\n",
    "        baseline = np.mean(traces, axis=1)\n",
    "\n",
    "    # calculate dF\n",
    "    df = traces.T-baseline\n",
    "    \n",
    "    \n",
    "    if not std_norm:\n",
    "        df = df/baseline\n",
    "    else:\n",
    "        df = df/(1+(np.std(traces, axis=0))/np.sqrt(traces.shape[0]))\n",
    "        #df = df/(1+(np.std(frames, axis=0)))\n",
    "            \n",
    "            \n",
    "    return df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp memo\n",
    "ET_video = open_raw_eye_file(ET_filename[0][1])\n",
    "ET_video.img_data.shape\n",
    "filename = ET_filename[0][0]\n",
    "print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=open(filename,'rb')\n",
    "version = int(np.frombuffer(a.read(4), dtype=np.uint32)[0])\n",
    "width = int(np.frombuffer(a.read(4), dtype=np.uint32)[0])\n",
    "height = int(np.frombuffer(a.read(4), dtype=np.uint32)[0])\n",
    "n_frames = int(np.frombuffer(a.read(4), dtype=np.uint32)[0])\n",
    "pixel_format = int(np.frombuffer(a.read(4), dtype=np.uint32)[0])\n",
    "print(version)\n",
    "print(width)\n",
    "print(height)\n",
    "print(n_frames)\n",
    "print(pixel_format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
